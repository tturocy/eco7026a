{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8cd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa6985",
   "metadata": {},
   "source": [
    "## Demographics: Standardising and recoding data fields\n",
    "\n",
    "Let's now turn to the individual demographics data, which we will tidy up a bit.  These are in the files called `demographics`.  We'll take a bit of a shortcut and not check the schemas are the same (exercise: try it yourself!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b90305",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_demographics = pd.concat(\n",
    "    [pd.read_csv(\"data/raw/batch1/demographics.csv\"), pd.read_csv(\"data/raw/batch2/demographics.csv\")],\n",
    "    ignore_index=True\n",
    ")\n",
    "raw_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9277363",
   "metadata": {},
   "source": [
    "Let's have a look at the columns and their data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_demographics.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98382b91",
   "metadata": {},
   "source": [
    "In this case we know the fields we're particularly interested in: the seven \"about you\" questions.  Let's have a look at the data values for them.  We can look at just a subset of the columns in a `DataFrame` by using the square-bracket operator.  We are passing a list of columns, hence we have double square brackets.  The outer pair of square brackets is the indexing operator, and the inner pair is what denotes the list.  (It is perhaps unfortunate that Python uses square brackets both for indexing and for delimiting a list....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10181aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_demographics[[\n",
    "    'player.gender', 'player.age', 'player.countryborn',\n",
    "    'player.countrynow', 'player.department', 'player.degree',\n",
    "    'player.timeuea'\n",
    "]].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c30fd",
   "metadata": {},
   "source": [
    "As before, we know we have entries for slots that were opened up for participants who did not turn up for the experiment.  However, trying to filter participants on whether or not demographics are null would be problematic, because participants cannot be obligated to disclose any or all of their demographic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153441ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_demographics[[\n",
    "    'player.gender', 'player.age', 'player.countryborn',\n",
    "    'player.countrynow', 'player.department', 'player.degree',\n",
    "    'player.timeuea'\n",
    "]].query(\"`player.department`.isnull()\").head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477f2f5",
   "metadata": {},
   "source": [
    "Here's where knowing how the software works is useful, including some of that data which is more about administering the experiment rather than collecting responses directly.  For each row there's a field called `participant._index_in_pages` (note the leading underscore), which tells you how far the participant has progressed in the experiment, and also `participant._max_page_index`, which is the total number of pages needed to complete the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf903d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_demographics[[\n",
    "    \"participant._index_in_pages\", \"participant._max_page_index\",\n",
    "    \"player.gender\", \"player.age\"\n",
    "]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b9dc9",
   "metadata": {},
   "source": [
    "The number of pages there are in a session depends on the session.  (As we were running the experiment, we realised having extra landing pages in the instructions was helpful to keep participants together.)  So the best way to test whether a participant row is a valid obseration is to see whether they reached the final page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_demographics.query(\"`participant._index_in_pages` == `participant._max_page_index`\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf3752",
   "metadata": {},
   "source": [
    "We've got the right number of rows.  We'll check later on whether our participant IDs match up exactly with what we did with decisions.  For now, let's continue cleaning the data by selecting the columns we want (and while we're at it, let's get rid of those annoying periods in the column names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.rename(columns=lambda x: x.replace(\".\", \"_\"))\n",
    "    .reindex(\n",
    "        columns=['session_label', 'participant_code',\n",
    "                 'player_gender', 'player_age', 'player_countryborn',\n",
    "                 'player_countrynow', 'player_department', 'player_degree',\n",
    "                 'player_timeuea']\n",
    "\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94a2bc",
   "metadata": {},
   "source": [
    "Sometimes, there are fields where there is a finite list of possible answers - but that list is too long to specify completely in a question.  Countries are a good example of this; there are roughly 200 in the world (depending on how you count), but we're all had the experience of how tedious it is to pick out your country from a long drop-down list.  We have two country fields in our data; this is a good opportunity to look at ways to tidy up the data.\n",
    "\n",
    "Let's first look at `countryborn`, and see what data values are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3441de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('player_countryborn')['player_countryborn'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf08c9e",
   "metadata": {},
   "source": [
    "Compared to some datasets, this isn't all that bad; most of the country names are already rather clean.  We just need to standardise a few country names, and to make a decision about how to code situations where more than one country is listed.\n",
    "\n",
    "To accomplish this we'll use two functions:\n",
    "1. `Series.str.title()`: This will convert all the strings to Title Case - that is, first letter of each work capitalised and all others lowercase; (https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.Series.str.title.html)\n",
    "2. `Series.replace()`: This takes a `dict`, and replaces each instance of a key with the corresponding value in the `dict`. (https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.Series.replace.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    player_countryborn = lambda x: (\n",
    "        x['player_countryborn'].str.title()\n",
    "        .replace(\n",
    "            {'Britain': 'United Kingdom',\n",
    "             'British': 'United Kingdom',\n",
    "             'Uk': 'United Kingdom',\n",
    "             'Uk (England)': 'United Kingdom',\n",
    "             'Uk, Australia': 'United Kingdom',\n",
    "             'England': 'United Kingdom',\n",
    "             'England / Uk': 'United Kingdom',\n",
    "             'United Kingdom (England)': 'United Kingdom',\n",
    "             'Denmark/Usa': 'Denmark',\n",
    "             'United States Of America': 'United States',\n",
    "             'Usa': 'United States',\n",
    "             'Taiwan, Egypt': 'Taiwan'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df.sort_values('player_countryborn')['player_countryborn'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70a67c",
   "metadata": {},
   "source": [
    "Looks good.  Now we'll do the same exercise with `player_countrynow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('player_countrynow')['player_countrynow'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26eabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    player_countrynow = lambda x: (\n",
    "        x['player_countrynow'].str.title()\n",
    "        .replace(\n",
    "            {'Britain': 'United Kingdom',\n",
    "             'British': 'United Kingdom',\n",
    "             'Uk': 'United Kingdom',\n",
    "             'Uk (England)': 'United Kingdom',\n",
    "             'Uk England': 'United Kingdom',\n",
    "             'Uk, Australia': 'United Kingdom',\n",
    "             'England, Uk': 'United Kingdom',\n",
    "             'England': 'United Kingdom',\n",
    "             'England / Uk': 'United Kingdom',\n",
    "             'Uk As A Visiting Student': 'United Kingdom',\n",
    "             'United Kingdom (England)': 'United Kingdom',\n",
    "             'Denmark/Usa': 'Denmark',\n",
    "             'United States Of America': 'United States',\n",
    "             'Usa': 'United States',\n",
    "             'Taiwan, Egypt': 'Taiwan'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df.sort_values('player_countrynow')['player_countrynow'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839dc9ea",
   "metadata": {},
   "source": [
    "Now let's have a look at `player_gender`.  This is an example of a quite annoying data field - the data are recorded by the computer as integers, but you have to know the computer code to know what is what.  Because we do have the computer code, we know that 1 = Male, 2 = Female, 3 = Other, and 4 = prefer not to say.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('player_gender')['participant_code'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f8503",
   "metadata": {},
   "source": [
    "We'll recode these using letters (M, F, O), and replace 4 with true null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    player_gender = lambda x: (\n",
    "        x['player_gender'].replace(\n",
    "            {1: 'M',\n",
    "             2: 'F',\n",
    "             3: 'O',\n",
    "             4: None}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df.groupby('player_gender')['participant_code'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baadbee",
   "metadata": {},
   "source": [
    "Now, let's have a look at the responses for UEA schools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b40a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('player_department')['player_department'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8e9bb",
   "metadata": {},
   "source": [
    "These aren't too bad.  To clean these up, alongside `Series.replace` which we've already used, we'll make use of two useful methods for string manipulation:\n",
    "\n",
    "1. `Series.str.upper()`: Converts all characters in the string to uppercase. (https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.Series.str.upper.html) \n",
    "2. `Series.str[]`: The `[]` notation on a Series works just like it does on regular Python strings or lists.  We'll use it here to restrict to the first three letters - which, after a bit of initial cleanup, maps to the UEA School/Faculty/programme names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    player_department=lambda x: (\n",
    "        x['player_department'].replace(\n",
    "            {\"BSc Psychology\": \"PSY\",\n",
    "             \"NMS\": \"MED\",\n",
    "             \"UEA\": None}\n",
    "        )\n",
    "        .str.upper()\n",
    "        .str[:3]\n",
    "    )\n",
    ")\n",
    "df.sort_values('player_department')['player_department'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289f3af",
   "metadata": {},
   "source": [
    "The UEA degree/affiliation field is, like gender, straightforward enough if you have the coding from the software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d119286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    player_degree=lambda x: (\n",
    "        x['player_degree'].replace(\n",
    "            {1: \"INTO\",\n",
    "             2: \"BSc\",\n",
    "             3: \"PGDip\",\n",
    "             4: \"MA/MSc\",\n",
    "             5: \"PhD\",\n",
    "             6: \"Staff\",\n",
    "             7: \"Other\",\n",
    "             8: None}\n",
    "        )        \n",
    "    )\n",
    ")\n",
    "df.sort_values('player_degree')['player_degree'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f20ecc",
   "metadata": {},
   "source": [
    "Likewise, coding up the time-at-UEA question is now routine (I hope!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    player_timeuea=lambda x: (\n",
    "        x['player_timeuea'].replace(\n",
    "            {1: \"1st\",\n",
    "             2: \"2nd\",\n",
    "             3: \"3rd\",\n",
    "             4: \"4th\",\n",
    "             5: \"5th+\",\n",
    "             6: None}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "df.sort_values('player_timeuea')['player_timeuea'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac6892",
   "metadata": {},
   "source": [
    "Let's take stock of where we are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a075b4",
   "metadata": {},
   "source": [
    "We haven't yet looked at the 'age' field.  We can have a look at the distribution of values in this field to see whether there are any which might be problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('player_age')[['participant_code']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee0adb",
   "metadata": {},
   "source": [
    "We're rather close; just a few further adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.rename(columns=lambda x: x.replace(\"player_\", \"\"))\n",
    "    .rename(columns={\n",
    "        'session_label': 'session_id',\n",
    "        'participant_code': 'participant_id'\n",
    "    })\n",
    "    .astype({'age': int})\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b489dc",
   "metadata": {},
   "source": [
    "We'll save our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = df\n",
    "demographics.to_csv(\"data/prepared/demographics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22980b0d",
   "metadata": {},
   "source": [
    "In experiments (whether lab or field), randomisation of participants into treatments is a crucial aspect of the research methodology.  For example, in this experiment, we want to isolate the effect of information provision.  Now, in naturally-occuring data, there may be different kinds of information provided by, for example, different investment platforms.  However, because people choose which investment platform to use, it might be that individual characteristics or preferences of people vary across different platforms.  For example, hypothetically, people who are risk-averse might prefer platforms that emphasise risk information.  Or, it could be - because people tend to avoid negative information - risk-averse people might prefer platforms that *don't* have risk information!  Either way, this would confound our understanding of the effect of information.\n",
    "\n",
    "Because we recruit participants into treatments at random, it should be the case that the characteristics of the participants in each treatment will be similar.  It is customary in experiments (especially field experiments) to check that the assignment of participants to treatments is similar based on their *observable* characteristics.\n",
    "\n",
    "Let's check a few of these as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fddca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = pd.read_csv(\"data/raw/sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f5084",
   "metadata": {},
   "source": [
    "We will augment the demographics `DataFrame` with the treatment.  To do this, we use the `merge` operation.\n",
    "(https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.DataFrame.merge.html).  See the somewhat deeper dive in the \"mini-focus\" on `merge` (and `join`) available in the `topics` notebook for this week.\n",
    "\n",
    "In our `sessions` data, we have only one row for each `session_id`.  So our resulting `DataFrame` should still have 200 rows - one for each participant in `demographics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c56465",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = demographics.merge(\n",
    "    sessions, how='left', on='session_id'\n",
    ")\n",
    "demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98354296",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = demographics.groupby(['treatment', 'gender'])[['participant_id']].count()\n",
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ffd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "department = (\n",
    "    demographics.assign(\n",
    "        is_eco=lambda x: x['department'] == \"ECO\"\n",
    "    )\n",
    "    .groupby(['treatment', 'is_eco'])[['participant_id']].count()\n",
    ")\n",
    "department.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ddd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = (\n",
    "    demographics.assign(\n",
    "        is_uk=lambda x: x['countryborn'] == \"United Kingdom\"\n",
    "    )\n",
    "    .groupby(['treatment', 'is_uk'])[['participant_id']].count()\n",
    ")\n",
    "country.unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf2c5da",
   "metadata": {},
   "source": [
    "## Numeracy data: Wide and long data formats\n",
    "\n",
    "We'll turn now to the data from the 7 economic/numeracy questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_numeracy = pd.concat(\n",
    "    [pd.read_csv(\"data/raw/batch1/numeracy.csv\"), pd.read_csv(\"data/raw/batch2/numeracy.csv\")],\n",
    "    ignore_index=True\n",
    ")\n",
    "raw_numeracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13aef4",
   "metadata": {},
   "source": [
    "In this experiment, the answers to the seven questions are coded in fields called `player.answer1` up to `player.answer7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_numeracy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d00205",
   "metadata": {},
   "source": [
    "We're only interested in the session/participant labels, and the answers to the seven questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_numeracy.reindex(\n",
    "    columns=['session.label', 'participant.code',\n",
    "             'player.answer1', 'player.answer2', 'player.answer3', 'player.answer4',\n",
    "             'player.answer5', 'player.answer6', 'player.answer7']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d1509",
   "metadata": {},
   "source": [
    "We'll get rid of those pesky full-stops in the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af921af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=lambda x: x.replace(\".\", \"_\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ed2c7",
   "metadata": {},
   "source": [
    "Answering the numeracy questions was compulsory - so we can identify which rows correspond to actual participant responses by looking at the answer to the first question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfd2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"player_answer1.notnull()\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d1d02",
   "metadata": {},
   "source": [
    "A bit of column renaming gets us to a first tidied-up representation of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60859fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeracy = (\n",
    "    df.rename(columns={'session_label': 'session_id',\n",
    "                       'participant_code': 'participant_id'})\n",
    "    .rename(columns=lambda x: x.replace(\"player_answer\", \"answer\"))\n",
    ")\n",
    "numeracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3e79ea",
   "metadata": {},
   "source": [
    "We're interested in how many questions participants got correct.  One way we could do this is by manually going through and assigning correct/incorrect for each of the seven questions, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a363c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    numeracy.assign(\n",
    "        correct1=lambda x: (x['answer1'] == 150).astype(int),\n",
    "        correct2=lambda x: (x['answer2'] == 100).astype(int),\n",
    "        correct3=lambda x: (x['answer3'] == 9000).astype(int),\n",
    "        correct4=lambda x: (x['answer4'] == 400000).astype(int),\n",
    "        correct5=lambda x: (x['answer5'] == 242).astype(int),\n",
    "        correct6=lambda x: (x['answer6'] == 3).astype(int),\n",
    "        correct7=lambda x: (x['answer7'] == 2).astype(int)\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc00b3",
   "metadata": {},
   "source": [
    "The numeracy score is then just the number of correct responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    numeracy=lambda x: x['correct1'] + x['correct2'] + x['correct3'] + x['correct4'] + x['correct5'] + x['correct6'] + x['correct7']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89a028",
   "metadata": {},
   "source": [
    "How did our participants do?  Quite well actually.  Frankly - too well.  We used these questions because in previous studies most people scored 3 or 4.  Our sample is far more numerate than the general public.  So - good on UEA students!  But in the end not as good for our research question..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbf73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('numeracy')[['participant_id']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e59ac",
   "metadata": {},
   "source": [
    "There is another way of computing these scores - one that involves less repetitive typing, and also would scale much better to different (and larger) numbers of questions.\n",
    "\n",
    "The data here are represented in \"wide\" format.  Each row corresponds to one participant, and within that participant we have multiple columns corresponding to responses to different questions.\n",
    "\n",
    "We can convert the data to \"long\" format.  In long format, each row corresponds to one participant's response to one question.  For this purpose we'll use the `wide_to_long` function.  (https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.wide_to_long.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.wide_to_long(numeracy, 'answer', ['session_id', 'participant_id'], 'question')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97345554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16307b",
   "metadata": {},
   "source": [
    "Long-format data is often easier to work with for doing various types of analyses.  For example, if you want to look at the distribution of responses across participants for each question, it is very easy to do with one line when you have the data in long format.  Doing this analysis with wide-format data would be much more cumbersome - we would have to iterate over each of the response columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['question', 'answer'])[['participant_id']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc74e641",
   "metadata": {},
   "source": [
    "Scoring the responses to be correct/incorrect is also much easier.  We can do this by creating an auxiliary `DataFrame` which gives the correct response to each question. We'll do that here by just making the `DataFrame` in memory - but for example if you had a much longer inventory of questions you might create this as another data file in your `raw` data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b283e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pd.DataFrame(\n",
    "    [(1, 150), (2, 100), (3, 9000), (4, 400000), (5, 242), (6, 3), (7, 2)],\n",
    "    columns=['question', 'correct']\n",
    ")\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe09a09",
   "metadata": {},
   "source": [
    "Then we can use a `merge` to add the correct answer to each row of our long-format `DataFrame`.  This is much more elegant, and more maintainable, than the way we did this in wide-format with `assign` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(correct, how='left', on=['question'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb483f8e",
   "metadata": {},
   "source": [
    "Likewise, scoring each question is now much easier to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965406bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    numeracy=lambda x: (x['answer'] == x['correct']).astype(int)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df.groupby(['participant_id'])[['numeracy']].sum()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b64ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.reset_index()\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9aafbd",
   "metadata": {},
   "source": [
    "And we can see that we get the same distribution of numeracy scores via the \"long-format\" route as we did via the \"wide-format\" route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.groupby('numeracy')[['participant_id']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915f39c",
   "metadata": {},
   "source": [
    "The inverse operation to `wide_to_long` is `pivot`.  (https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.DataFrame.pivot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot(df, index=['session_id', 'participant_id'], columns='question', values=['answer', 'correct', 'numeracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc408c",
   "metadata": {},
   "source": [
    "Although we got less variation in the numeracy scores than we predicted, it is also still interesting to look to see whether numeracy correlates with any other demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_csv(\"data/prepared/demographics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51430fe5",
   "metadata": {},
   "source": [
    "In what I hope is now starting to feel routine, we'll take our numeracy scores and merge them with the demographics by `participant_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e800cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.merge(demographics, how='left', on='participant_id')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659704d",
   "metadata": {},
   "source": [
    "We can look at the relationship between gender and numeracy score.  First we could just look at average scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dfc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.groupby('gender')[['numeracy']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c3d80",
   "metadata": {},
   "source": [
    "But it's often more informative to do a cross-tabulation breakdown.  Following a similar pattern as before,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scores.groupby(['gender', 'numeracy'])[['participant_id']].count()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5476a",
   "metadata": {},
   "source": [
    "As we observed already, it turned out we had rather more females than males in our study.  So it would be useful to convert the numeracy scores into percentages.  We can accomplish this by grouping and then calling `transform`.  (https://pandas.pydata.org/pandas-docs/version/1.2.4/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(level=0).transform(lambda x: x/sum(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57575fb9",
   "metadata": {},
   "source": [
    "You might like to round the percentages for easier viewing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98053f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.assign(\n",
    "    is_eco=lambda x: x['department'] == \"ECO\"\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150ad97",
   "metadata": {},
   "source": [
    "What about ECO students?  Do ECO students score more highly on numeracy than others?\n",
    "\n",
    "We can follow the same pattern as above - but exercise our fluent-interface muscles to write the algorithm for computing the table compactly as a single expression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    scores.groupby(['is_eco', 'numeracy'])[['participant_id']].count()\n",
    "    .groupby(level=0).transform(lambda x: x/sum(x))\n",
    "    .unstack(1, fill_value=0)\n",
    "    .round(2)\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
